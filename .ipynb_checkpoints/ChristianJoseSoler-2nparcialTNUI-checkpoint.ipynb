{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2n Parcial 2016\n",
    "\n",
    "## Classificació de llenguatges de programació\n",
    "\n",
    "En aquest examen haureu d'utilitzar Naie Bayes per tal de classificar un arxiu com a Python o Java.\n",
    "\n",
    "\n",
    "### Càrrega del corpus\n",
    "\n",
    "Tot i que ja està fet, és important entendre el format de les dades. Aquesta cel·la llegeix tots els arxius i separa el text resultant per espais, signes de puntuació, caràcters especials, etc.\n",
    "\n",
    "El resultat són 2 variables per cada llenguatge, una que conforma el 80% de les dades (train) i l'altre el 20% (test):\n",
    "\n",
    "* Les dades de train estan organitzades directament en una sola llista on cada element és una paraula o caràcter resultant de la separació\n",
    "\n",
    "```python\n",
    "train = ['token', 'paraula', 'paraula', ...]\n",
    "```\n",
    "\n",
    "* De forma similar, test és una llista però cada element és un arxiu diferent que, a la vegada, és el resultat de separar:\n",
    "\n",
    "```python\n",
    "train = [['token', 'paraula', 'paraula', ...], ['token', 'paraula', 'paraula', ...]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Christian José Soler\n",
    "\n",
    "## Parcial 2 TNUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "import sys\n",
    "\n",
    "# Glob pattern search on directories (might be recursive)\n",
    "def glob(path, ext, recursive=True):\n",
    "    if recursive:\n",
    "        for root, dirnames, filenames in os.walk(path):\n",
    "            for filename in fnmatch.filter(filenames, '*' + ext):\n",
    "                yield os.path.join(root, filename)\n",
    "    else:\n",
    "        for filename in fnmatch.filter(os.listdir(path), '*' + ext):\n",
    "            yield os.path.join(path, filename)\n",
    "\n",
    "# Splits a file by lines and then, each line is splitted by the supplied tokens\n",
    "def split_lines(f, delims=[';', '(', '[', ']', ')', ':', '=','.','-','+','/','*', ' ']):\n",
    "    with open(f) as fp:\n",
    "        for line in fp:\n",
    "            prev = 0\n",
    "            for i in range(len(line) - 1):\n",
    "                if line[i] in delims:\n",
    "                    n = i + 1\n",
    "                    while line[n] == line[i]: n += 1\n",
    "                    \n",
    "                    s = line[prev:n - 1]\n",
    "                    t = line[i]\n",
    "                    \n",
    "                    # Do not keep empty strings (or spaces only)\n",
    "                    if s.strip():\n",
    "                        yield s\n",
    "                        \n",
    "                        # Also yield tokens unless it is a space\n",
    "                        if t != ' ':\n",
    "                            yield t\n",
    "                    \n",
    "                    prev = n\n",
    "\n",
    "# Returns the parsed corpus\n",
    "def get_corpus(path, ext, recursive=False, test_size=0.2):\n",
    "    files = list(glob(path, ext, recursive))\n",
    "    \n",
    "    # Randomly select for train and test\n",
    "    split = int(len(files) * test_size)\n",
    "    test = files[:split]\n",
    "    train = files[split:]\n",
    "    \n",
    "    train_text = [list(split_lines(f)) for f in train]\n",
    "    test_text = [list(split_lines(f)) for f in test]\n",
    "    return sum(train_text, []), test_text\n",
    "    \n",
    "\n",
    "#########################\n",
    "# VARIABLES A UTILITZAR #\n",
    "#########################\n",
    "python_train_corpus, python_test_corpus = get_corpus('corpus/python', '.py', True)\n",
    "java_train_corpus, java_test_corpus = get_corpus('corpus/java', '.java', True)\n",
    "java_train_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercici 1: Bigrames i unigrames (2 punts)\n",
    "\n",
    "**Implementa** una funció que donat el corpus d'entrenament (amb el format indicat adalt) d'un llenguatge retorni:\n",
    "\n",
    "1. Un diccionari amb els unigrames d'aquest llenguatge com a clau i el número d'ocurrències com a valor\n",
    "2. Un diccionari amb els bigrames d'auqest llenguatge com a clau i el número d'ocurrències com a valor\n",
    "\n",
    "Recorda que:\n",
    "\n",
    "* Un unigrama és la unitat més petita, una sola paraula o token\n",
    "* Un bigrama és un conjunt de dues paraules o tokens seguits\n",
    "\n",
    "*Nota*: Per facilitar aquest exercici i els següents us recomanem que guardeu els bigrames com a tuples: $(x_0, x_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def find_unigrams_bigrams(corpus):\n",
    "    unigrams = Counter(corpus)\n",
    "    bigrams = []\n",
    "    for i in xrange(len(corpus)-1):\n",
    "        bigrams.append((corpus[i], corpus[i+1]))\n",
    "    bigrams = Counter(bigrams)\n",
    "    \n",
    "    return unigrams, bigrams\n",
    "\n",
    "python_unigrams, python_bigrams = find_unigrams_bigrams(python_train_corpus)\n",
    "java_unigrams, java_bigrams = find_unigrams_bigrams(java_train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercici 2: Bigrames representatius (1 punt)\n",
    "\n",
    "Ara que ja tens els bigrames, **implementa** una funció que retorni els $N$ bigrames més representatius. Pren com a més representatius els $N$ més comuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_N_grams(bigrams, N):\n",
    "    return bigrams.most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "print top_N_grams(python_bigrams, N)\n",
    "print top_N_grams(java_bigrams, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercici 3: Probabilitat d'un bigrama (3 punts)\n",
    "\n",
    "Podem definir la probabilitat d'un bigrama $X_i = (x_0, x_1)_i$ per a una llenguatge $L_j$ com:\n",
    "\n",
    "* Si el bigrama es troba en el conjunt de bigrames del llenguatge:\n",
    "   \n",
    "    $$P(X|L=l_j) = \\dfrac{\\text{Ocurrències }X_i\\text{ en l_j}}{\\text{Total d'ocurrències en bigrames}\\text{ en l_j}}$$\n",
    "   \n",
    "   \n",
    "* Si el bigrama no es troba però les dues paraules que el conformen si estan en els unigrames:\n",
    "\n",
    "    $$P(X|L=l_j) = \\dfrac{\\text{Ocurrències }x_{0}\\text{ en l_j}}{\\text{Total d'ocurrències en unigrames}\\text{ en l_j}} \\cdot \\dfrac{ \\text{Ocurrències }x_{1}\\text{ en l_j}}{\\text{Total d'ocurrències en unigrames}\\text{ en l_j}}$$\n",
    "\n",
    "\n",
    "* En cas contrari:\n",
    "\n",
    "    $$P(X|L=l_j) = \\dfrac{1}{\\text{Total d'ocurrències en bigrames}\\text{ en l_j}}$$\n",
    "    \n",
    "    \n",
    "------------------\n",
    "\n",
    "**Implementa**:\n",
    "\n",
    "* Una funció que faci els càlculs de dalt per a un bigrama i els unigrames i bigrames d'un llenguatge donat\n",
    "* Codi que faci servir la funció per calcular la probabilitat de tots els N bigrames més comuns, per cada llenguatge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prob(X, bigrams, unigrams):\n",
    "    total_unigrams = sum(unigrams.values())\n",
    "    total_bigrams = sum(bigrams.values())    \n",
    "    if X in bigrams:\n",
    "        p = float(bigrams[X]) / float(total_bigrams)\n",
    "    elif X[0] in unigrams and X[1] in unigrams:\n",
    "        p = float(unigrams[X[0]] * unigrams[X[1]]) / float(total_unigrams**2)\n",
    "    else:\n",
    "        p = 1.0 / float(total_bigrams)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tots els N bigrames en comú\n",
    "all_N = set(top_N_grams(python_bigrams, N) + top_N_grams(java_bigrams, N))\n",
    "python_probs = map(lambda x: prob(x, python_bigrams, python_unigrams), all_N)\n",
    "java_probs = map(lambda x: prob(x, java_bigrams, java_unigrams), all_N)\n",
    "# Càlcul de les probabilitats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercici 4: Vector de característiques (1.5 punts)\n",
    "\n",
    "Per cada arxiu del conjunt de test, és a dir cada element de la llista, fes el vector de caracteristiques binari, es a dir:\n",
    "\n",
    "* Aquest conté 1 a la posició $i$ si l'arxiu té el bigrama $i$\n",
    "* En cas contrari, si no té el bigrama, conté un 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_vector(test_corpus, all_N):\n",
    "    features = []\n",
    "    for f in test_corpus:\n",
    "        tmp_set = set()\n",
    "        for i in xrange(len(f)-1):\n",
    "            tmp_set.add((f[i], f[i+1]))\n",
    "        features.append(map(lambda x: 1 if x in tmp_set else 0, all_N))\n",
    "    \n",
    "    return features\n",
    "    \n",
    "python_feature_vector = feature_vector(python_test_corpus, all_N)\n",
    "java_feature_vector = feature_vector(java_test_corpus, all_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercici 5: Classificar (2.5 punts)\n",
    "\n",
    "Finalment, ara cal que per cada arxiu de test, dels quals ja has creat el vector de característiques, el classifiquis. Per fer-ho, implementa Naive Bayes, això és:\n",
    "\n",
    "$$P(Y=(X_1, X_2, ..., X_n)|L) = P(X_1|L)\\cdot P(X_2|L)\\cdot ...\\cdot P(X_n|L)\\cdot P(L)$$\n",
    "\n",
    "On cada $X_i$ és un dels bigrames. A més, pots assumir que $P(L_{python}) = P(L_{java}) = 0.5$, pel que pots ometre el terme. Tingues en compte el que implica tenir un 0 en el vector de característiques.\n",
    "\n",
    "Per tant, cal calcular $P(Y|L_{python})$ i $P(Y|L_{java})$, i la classificació serà:\n",
    "\n",
    "$$\\text{llenguatge} = max_L(P(Y|L_{python}), P(Y|L_{java}))$$\n",
    "\n",
    "**Implementa-ho seguint la formulació d'adalt, sense modificacions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(features, python_probs, java_probs):\n",
    "    classes = []\n",
    "    for elem in features:\n",
    "        py_prob = 1.0\n",
    "        jv_prob = 1.0\n",
    "        for i in xrange(len(elem)):\n",
    "            ## Que hi hagi un 0 al vector vol dir que la probabilitat que busquem és del 1-p\n",
    "            py_prob *= python_probs[i] if elem[i] else (1.0 - python_probs[i])\n",
    "            jv_prob *= java_probs[i] if elem[i] else (1.0 - java_probs[i])\n",
    "            \n",
    "            #### Per corregir l'underflow ####\n",
    "            #py_prob += log(python_probs[i]) if elem[i] else log(1-python_probs[i])\n",
    "            #jv_prob += log(java_probs[i]) if elem[i] else log(1-java_probs[i])\n",
    "        if py_prob > jv_prob:\n",
    "            classes.append(\"python\")\n",
    "        elif py_prob < jv_prob:\n",
    "            classes.append(\"java\")\n",
    "        else:\n",
    "            classes.append(\"unknown\")\n",
    "    return classes\n",
    "\n",
    "python_results = classify(python_feature_vector, python_probs, java_probs)\n",
    "java_results = classify(java_feature_vector, python_probs, java_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respon**:\n",
    "\n",
    "* Quin és el rati d'encerts pels arxius de Python? i pels de Java?\n",
    "* Quin problema té el càlcul tal i com està adalt? Com es pot evitar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### El rati d'encerts pels dos és del 100%\n",
    "\n",
    "#### El problema possible és d'underflow, es pot corregir fent servir logaritmes i sumant les probabilitats, enlloc de multiplicar-les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
